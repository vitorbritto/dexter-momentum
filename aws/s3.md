# Amazon S3 (Simple Storage Service)

Amazon S3 é um serviço de armazenamento de objetos totalmente gerenciado que oferece escalabilidade, disponibilidade de dados, segurança e performance líderes de mercado. É um dos serviços mais fundamentais da AWS, usado para armazenar e recuperar qualquer quantidade de dados a qualquer momento.

## Características Principais

### Armazenamento de Objetos

S3 armazena dados como objetos em buckets, diferente de sistemas de arquivos tradicionais. Cada objeto consiste em:
- **Key**: Nome único do objeto (como um caminho de arquivo)
- **Value**: Dados do objeto
- **Version ID**: ID da versão (se versionamento está habilitado)
- **Metadata**: Metadados sobre o objeto

### Escalabilidade Ilimitada

S3 pode armazenar praticamente qualquer quantidade de dados sem limites pré-definidos. Escala automaticamente conforme sua necessidade.

### Durabilidade e Disponibilidade

- **Durabilidade**: 99.999999999% (11 noves) - objetos são armazenados em múltiplas instalações
- **Disponibilidade**: Varia por classe de armazenamento (99.99% para Standard)

### Serverless

S3 é totalmente gerenciado - você não precisa provisionar servidores ou gerenciar infraestrutura.

## Conceitos Fundamentais

### Buckets

Buckets são containers para objetos:
- Nome deve ser globalmente único
- Residem em uma região específica
- Podem conter quantos objetos quiser
- Organizam objetos de forma hierárquica

### Objetos

Objetos são os arquivos que você armazena:
- Tamanho máximo: 5 TB
- Cada objeto tem uma chave (key) única
- Podem ter metadados customizados
- Suportam tags para organização

### Keys

Keys são identificadores únicos para objetos:
- Similar a caminhos de arquivo: `folder1/folder2/file.txt`
- Usadas para organizar objetos hierarquicamente
- Case-sensitive

### Regions

Buckets são criados em regiões específicas:
- Escolha a região mais próxima aos usuários
- Dados não saem da região por padrão
- Pode configurar replicação entre regiões

## Classes de Armazenamento

### S3 Standard

- Acesso frequente
- Baixa latência e alta throughput
- Ideal para: websites, distribuição de conteúdo, análise de dados

### S3 Intelligent-Tiering

- Move automaticamente objetos entre tiers baseado em padrões de acesso
- Sem taxas de recuperação
- Ideal para: dados com padrões de acesso desconhecidos

### S3 Standard-IA (Infrequent Access)

- Acesso infrequente
- Menor custo de armazenamento, taxa de recuperação
- Ideal para: backups, dados de longa duração

### S3 One Zone-IA

- Similar ao Standard-IA, mas armazenado em uma única zona de disponibilidade
- 20% mais barato que Standard-IA
- Ideal para: dados que podem ser recriados

### S3 Glacier Instant Retrieval

- Acesso em milissegundos
- Ideal para: arquivos raramente acessados que precisam de acesso rápido quando necessário

### S3 Glacier Flexible Retrieval

- Recuperação em 1-5 minutos (expedited) ou 3-5 horas (standard)
- Ideal para: backups e arquivos de longo prazo

### S3 Glacier Deep Archive

- Mais barato
- Recuperação em 12 horas
- Ideal para: retenção de longo prazo (7-10 anos)

### S3 Outposts

- Armazenamento S3 em suas próprias instalações
- Para requisitos de residência de dados

## Operações Básicas

### Upload de Objeto

```javascript
const AWS = require('aws-sdk');
const s3 = new AWS.S3();

const params = {
  Bucket: 'my-bucket',
  Key: 'folder/file.txt',
  Body: 'Hello, S3!',
  ContentType: 'text/plain'
};

await s3.putObject(params).promise();
```

### Download de Objeto

```javascript
const params = {
  Bucket: 'my-bucket',
  Key: 'folder/file.txt'
};

const data = await s3.getObject(params).promise();
const content = data.Body.toString();
```

### Listar Objetos

```javascript
const params = {
  Bucket: 'my-bucket',
  Prefix: 'folder/'
};

const data = await s3.listObjectsV2(params).promise();
data.Contents.forEach(obj => {
  console.log(obj.Key);
});
```

### Deletar Objeto

```javascript
const params = {
  Bucket: 'my-bucket',
  Key: 'folder/file.txt'
};

await s3.deleteObject(params).promise();
```

## Versionamento

Versionamento mantém múltiplas versões de um objeto:
- Permite recuperar versões anteriores
- Protege contra exclusão acidental
- Cada versão tem um ID único

### Habilitar Versionamento

```javascript
await s3.putBucketVersioning({
  Bucket: 'my-bucket',
  VersioningConfiguration: {
    Status: 'Enabled'
  }
}).promise();
```

## Lifecycle Policies

Lifecycle policies automatizam transições entre classes de armazenamento e exclusão:

```json
{
  "Rules": [
    {
      "Id": "Move to Glacier",
      "Status": "Enabled",
      "Transitions": [
        {
          "Days": 90,
          "StorageClass": "GLACIER"
        }
      ]
    },
    {
      "Id": "Delete old versions",
      "Status": "Enabled",
      "NoncurrentVersionExpiration": {
        "NoncurrentDays": 365
      }
    }
  ]
}
```

## CORS (Cross-Origin Resource Sharing)

Configure CORS para permitir acesso de outros domínios:

```json
[
  {
    "AllowedHeaders": ["*"],
    "AllowedMethods": ["GET", "PUT", "POST", "DELETE"],
    "AllowedOrigins": ["https://example.com"],
    "ExposeHeaders": ["ETag"],
    "MaxAgeSeconds": 3000
  }
]
```

## Eventos e Notificações

S3 pode notificar outros serviços quando eventos ocorrem:

### Eventos Suportados

- `s3:ObjectCreated:*` - Objeto criado
- `s3:ObjectCreated:Put` - Upload via PUT
- `s3:ObjectCreated:Post` - Upload via POST
- `s3:ObjectCreated:Copy` - Cópia de objeto
- `s3:ObjectRemoved:*` - Objeto deletado
- `s3:ObjectRemoved:Delete` - Exclusão
- `s3:ObjectRemoved:DeleteMarkerCreated` - Marker de exclusão criado

### Destinos

- **SQS**: Enviar para fila
- **SNS**: Enviar notificação
- **Lambda**: Executar função
- **EventBridge**: Enviar evento

### Exemplo: Lambda Trigger

```javascript
// Lambda function triggered by S3
exports.handler = async (event) => {
  for (const record of event.Records) {
    const bucket = record.s3.bucket.name;
    const key = record.s3.object.key;
    
    console.log(`Novo objeto: s3://${bucket}/${key}`);
    // Processar objeto
  }
};
```

## Presigned URLs

URLs pré-assinadas permitem acesso temporário a objetos sem credenciais AWS:

```javascript
// Gerar URL válida por 1 hora
const url = s3.getSignedUrl('getObject', {
  Bucket: 'my-bucket',
  Key: 'folder/file.txt',
  Expires: 3600
});

// URL pode ser compartilhada e usada por qualquer pessoa
```

## Static Website Hosting

S3 pode hospedar websites estáticos:

1. Habilitar website hosting no bucket
2. Configurar index document (ex: `index.html`)
3. Configurar error document (ex: `error.html`)
4. Acessar via endpoint: `http://bucket-name.s3-website-region.amazonaws.com`

### Exemplo de Configuração

```javascript
await s3.putBucketWebsite({
  Bucket: 'my-website',
  WebsiteConfiguration: {
    IndexDocument: { Suffix: 'index.html' },
    ErrorDocument: { Key: 'error.html' }
  }
}).promise();
```

## Segurança

### Encryption

S3 suporta criptografia:
- **SSE-S3**: Criptografia gerenciada pela AWS
- **SSE-KMS**: Criptografia usando AWS KMS
- **SSE-C**: Criptografia com chaves fornecidas pelo cliente
- **Client-side**: Criptografar antes de upload

### Bucket Policies

Políticas de bucket controlam acesso:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "PublicReadGetObject",
      "Effect": "Allow",
      "Principal": "*",
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::my-bucket/*"
    }
  ]
}
```

### ACLs (Access Control Lists)

Controle de acesso granular por objeto ou bucket.

### Block Public Access

Bloqueia acesso público ao bucket e objetos:
- Bloqueia políticas públicas
- Bloqueia ACLs públicas
- Proteção adicional de segurança

## Transfer Acceleration

Acelera uploads usando CloudFront edge locations:
- Útil para uploads de longa distância
- Reduz latência
- Custo adicional

## Multipart Upload

Para objetos grandes (>5MB), use multipart upload:
- Divide objeto em partes
- Upload paralelo
- Mais eficiente e resiliente

```javascript
const upload = s3.createMultipartUpload({
  Bucket: 'my-bucket',
  Key: 'large-file.zip'
}).promise();

// Upload partes em paralelo
// Complete multipart upload
```

## Boas Práticas

### Organização

1. **Use prefixos para organização**: `folder1/folder2/file.txt`
2. **Nomeie buckets descritivamente**: `my-company-production-data`
3. **Use tags para categorização**: Ambiente, projeto, tipo de dado
4. **Considere partições por data**: `year=2024/month=01/file.txt`

### Performance

1. **Use multipart upload para arquivos grandes**: >5MB
2. **Paralelize requests**: Múltiplas requisições simultâneas
3. **Use CloudFront para distribuição**: Reduz latência
4. **Escolha classe de armazenamento apropriada**: Baseado em padrão de acesso

### Custo

1. **Configure lifecycle policies**: Mover para classes mais baratas
2. **Delete objetos não utilizados**: Reduz custos de armazenamento
3. **Use Intelligent-Tiering**: Para padrões desconhecidos
4. **Monitore uso**: Use S3 Storage Lens para insights

### Segurança

1. **Bloqueie acesso público por padrão**: Use Block Public Access
2. **Use IAM policies**: Controle acesso granularmente
3. **Habilite versionamento**: Para dados críticos
4. **Habilite logging**: S3 Access Logging para auditoria
5. **Use encryption**: Sempre criptografe dados sensíveis

### Durabilidade

1. **Habilite versionamento**: Para dados críticos
2. **Configure replication**: Para redundância entre regiões
3. **Use MFA Delete**: Proteção adicional contra exclusão
4. **Configure lifecycle**: Gerenciar ciclo de vida dos dados

## Casos de Uso

- **Backup e Archive**: Backup de dados, arquivamento de longo prazo
- **Static Website Hosting**: Hospedar websites estáticos
- **Data Lakes**: Armazenamento para análise de big data
- **Content Distribution**: Distribuir conteúdo (vídeos, imagens)
- **Disaster Recovery**: Armazenamento para DR
- **Application Data**: Armazenar dados de aplicações
- **Log Storage**: Armazenar logs de aplicações
- **Media Storage**: Armazenar mídia (vídeos, áudio, imagens)

